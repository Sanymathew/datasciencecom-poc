{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State\n",
      "Account Length\n",
      "Area Code\n",
      "Phone\n",
      "Int'l Plan\n",
      "VMail Plan\n",
      "VMail Message\n",
      "Day Mins\n",
      "Day Calls\n",
      "Day Charge\n",
      "Eve Mins\n",
      "Eve Calls\n",
      "Eve Charge\n",
      "Night Mins\n",
      "Night Calls\n",
      "Night Charge\n",
      "Intl Mins\n",
      "Intl Calls\n",
      "Intl Charge\n",
      "CustServ Calls\n",
      "Churn?\n",
      "State              object\n",
      "Account Length      int64\n",
      "Area Code           int64\n",
      "Phone              object\n",
      "Int'l Plan         object\n",
      "VMail Plan         object\n",
      "VMail Message       int64\n",
      "Day Mins          float64\n",
      "Day Calls           int64\n",
      "Day Charge        float64\n",
      "Eve Mins          float64\n",
      "Eve Calls           int64\n",
      "Eve Charge        float64\n",
      "Night Mins        float64\n",
      "Night Calls         int64\n",
      "Night Charge      float64\n",
      "Intl Mins         float64\n",
      "Intl Calls          int64\n",
      "Intl Charge       float64\n",
      "CustServ Calls      int64\n",
      "Churn?             object\n",
      "dtype: object\n",
      "State              object\n",
      "Account Length      int64\n",
      "Area Code           int64\n",
      "Phone              object\n",
      "Int'l Plan         object\n",
      "VMail Plan         object\n",
      "VMail Message       int64\n",
      "Day Mins          float64\n",
      "Day Calls           int64\n",
      "Day Charge        float64\n",
      "Eve Mins          float64\n",
      "Eve Calls           int64\n",
      "Eve Charge        float64\n",
      "Night Mins        float64\n",
      "Night Calls         int64\n",
      "Night Charge      float64\n",
      "Intl Mins         float64\n",
      "Intl Calls          int64\n",
      "Intl Charge       float64\n",
      "CustServ Calls      int64\n",
      "Churn?             object\n",
      "dtype: object\n",
      "Accuracy :  0.944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# <h1>Predicting Customer Churn in a Telecom Company</h1>\n",
    "# <p>This notebook is to demonstrate a simple machine learning problem using Jupyter notebooks and the datascience.com platform. The dataset that I've used in this example is from telecom customer data set which can be downloaded <a href=\"http://www.dataminingconsultant.com/data/churn.txt\"> here </a> </p>\n",
    "# <p>Each record in this dataset is a customer of this company and has customer attributes such as phone number, call minutes and so on. The dependent variable is 'Churn', which indicates if the customer is still a customer or has cancelled the service. And as expected - our goal in this exercise is to predict if the customer will churn or not, based on the attributes that are readily available to us.</p>\n",
    "\n",
    "# # Importing the data\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_curve\n",
    "import numba\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "\n",
    "# ### Let's take a look at what columns are part of the dataset and what a sample of the dataset looks like :\n",
    "\n",
    "# Use pandas read_csv function to read the file from the url above. \n",
    "# ``` python\n",
    "# churnData = pd.read_csv('http://www.dataminingconsultant.com/data/churn.txt')\n",
    "# ```\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "churnData = pd.read_csv('http://www.dataminingconsultant.com/data/churn.txt')\n",
    "\n",
    "\n",
    "# Columns in the dataset : \n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "for i in churnData.columns.tolist():\n",
    "    print(i)\n",
    "\n",
    "\n",
    "# A sample of the dataset : \n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "churnData.head(10)\n",
    "\n",
    "\n",
    "# Check the column datatypes : \n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "print(churnData.dtypes)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "# convert the ones with object to string \n",
    "obj_col = churnData.select_dtypes(include =[np.object]).columns.tolist()\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "churnData[obj_col] = churnData[obj_col].astype('str')\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "print(churnData.dtypes)\n",
    "\n",
    "\n",
    "# ## Exploratory analysis\n",
    "# Let's do some exploratory analysis to learn more about the dataset.\n",
    "# We'll start with looking at some preliminary distributions. \n",
    "# \n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# sns.factorplot( 'Churn?', data=churnData, kind = 'count')\n",
    "\n",
    "\n",
    "# The above visualization shows the distribution of the churned customers vs the non-churned customers in the dataset. Now lets compare the other variables in the dataset against churn? and see if it is indicative of anything. \n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# sns.boxplot(x=\"Churn?\", y=\"Account Length\", data=churnData)\n",
    "\n",
    "\n",
    "# It's interesting to observe that the account duration has no effect on the customers decision to churn. \n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# sns.boxplot(x=\"Churn?\",y=\"CustServ Calls\",data=churnData)\n",
    "\n",
    "\n",
    "# We see that the range of average number of customer service calls by customers who ended up churning are a bit wider than the ones that didn't end up churning. Though the results isn't statistically significant at this point, this could be a feature that will help us predict if a customer churns or not\n",
    "\n",
    "# We could continue our exploration and draw plots with other variables to observe their relationship amongst the independent and dependent variables. But for the sake of this demo, i'll stop here and proceed to predictive modelling stage. \n",
    "\n",
    "# ## Preparing the data for modelling \n",
    "# In this example, we'll use the random forest model to predict if the customer churns or not. We need to prepare our dataset for modelling, for example, change strings into numeric factors that the model can understand or remove variable that we don't think will be useful in the modelling process. \n",
    "# \n",
    "# The dependent variable is presently 'True.' or 'False.' We need to change this to 1 and 0 to give a boolean representation to this. \n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "churnData['Churn'] = churnData['Churn?'].map(lambda x: 1 if x=='True.' else 0)\n",
    "\n",
    "\n",
    "# Let's remove the variables that we think won't be useful in this example. In this case, we'll remove the Area Code ,Phone, State. We'll also remove the Churn? variable now that we have encoded the value in the 'Churn' variable instead. \n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# remove columns that we won't use \n",
    "churnData1 = churnData.drop(['Area Code','Phone','State','Churn?'],axis=1)\n",
    "\n",
    "\n",
    "# Convert the object variables and create dummy variables. \n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "# find out which columns are object type and convert them to dummy vars\n",
    "list_ = list(churnData1.select_dtypes(include=[np.object]).columns)\n",
    "churnData2 = pd.get_dummies(churnData1, prefix=list_)\n",
    "\n",
    "\n",
    "# Let's take a look at the data set now and them combine them with the rest of the dataset\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "churnData2.head()\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "# # merge with the other columns\n",
    "# list_nonObj = list(churnData.select_dtypes(exclude=['object']).columns)\n",
    "# churnData3 = churnData[list_nonObj]\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "inputData = churnData2\n",
    "\n",
    "\n",
    "# ### Final Input Dataset\n",
    "# This is what our final input dataset looks like. \n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "inputData.head()\n",
    "\n",
    "\n",
    "# We'll split the dataset into training and testing datasets. \n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "# split the input data set into train and test \n",
    "churnData_train, churnData_test = train_test_split(inputData, test_size =0.3)\n",
    "\n",
    "\n",
    "# Get the list of input features\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "features = inputData.drop(['Churn'], axis=1).columns\n",
    "\n",
    "\n",
    "# ### Training the model \n",
    "# We'll pass the input dataset to the random forest classifier to generate the model that will predict customer churn.\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "rcClassifier = RandomForestClassifier(n_estimators=40)\n",
    "rcClassifier.fit(churnData_train[features], churnData_train['Churn'])\n",
    "\n",
    "\n",
    "# ### Making Predictions\n",
    "# We'll pass our test set into the model to get the predictions and the probabilty associated with each prediction\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "# Make Predictions\n",
    "predictions = rcClassifier.predict(churnData_test[features])\n",
    "probabilities = rcClassifier.predict_proba(churnData_test[features])\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "score = rcClassifier.score(churnData_test[features],churnData_test['Churn'])\n",
    "print \"Accuracy : \", score\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "featureImportances = rcClassifier.feature_importances_\n",
    "featureImportanceIndex = np.argsort(rcClassifier.feature_importances_)[::-1]\n",
    "featureLabels = churnData_test.columns\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "columnsImportant = churnData_test.iloc[:,featureImportanceIndex.tolist()].columns\n",
    "\n",
    "\n",
    "# ## Plotting the feature importances \n",
    "# Let's take a look at what feature is important to predict if a customer will churn. \n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "# plt.title(\"Feature Importances\")\n",
    "# plt.barh(range(10), featureImportances[featureImportanceIndex][:10][::-1], color='b', align='center')\n",
    "# plt.yticks(range(10), columnsImportant[:10][::-1]) \n",
    "# plt.xlabel('Relative Importance')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# We observe that day charge,  day minutes, customer service calls  are the some of the important features that the model suggests. Let's plot the day charge, evening charge, and night charge and observe if there is any difference between them.\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "# sns.boxplot(y='Day Charge', x = 'Churn?', data=churnData)\n",
    "# sns.boxplot(y='Eve Charge', x = 'Churn?', data=churnData,color='g')\n",
    "# sns.boxplot(y='Night Charge', x = 'Churn?', data=churnData, color ='r')\n",
    "\n",
    "\n",
    "# ### Recommendations \n",
    "# 1. Reduce day charges. \n",
    "# 2. Bring on some loyalty program\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# function that takes a input dataset without the churn column and returns predictions, probabilities\n",
    "@numba.jit\n",
    "def predictCustChurn(x):\n",
    "    x = pd.read_json(x,orient='split')\n",
    "    pred = rcClassifier.predict(x)\n",
    "    probs = rcClassifier.predict_proba(x)\n",
    "    print probs\n",
    "    print probs[:,0]\n",
    "    print probs[:,1]\n",
    "    resp = {'pred':pred, 'probs_no':probs[:,0], 'probs_yes':probs[:,0]}\n",
    "    df = pd.DataFrame(data=resp)\n",
    "    result = df.to_json(orient='split')\n",
    "    return result\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.975  0.025]\n",
      " [ 1.     0.   ]]\n",
      "\n",
      "[ 0.975  1.   ]\n",
      "\n",
      "[ 0.025  0.   ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "res = predictCustChurn(\"{\\\"columns\\\":[\\\"Account Length\\\",\\\"VMail Message\\\",\\\"Day Mins\\\",\\\"Day Calls\\\",\\\"Day Charge\\\",\\\"Eve Mins\\\",\\\"Eve Calls\\\",\\\"Eve Charge\\\",\\\"Night Mins\\\",\\\"Night Calls\\\",\\\"Night Charge\\\",\\\"Intl Mins\\\",\\\"Intl Calls\\\",\\\"Intl Charge\\\",\\\"CustServ Calls\\\",\\\"Int'l Plan_no\\\",\\\"Int'l Plan_yes\\\",\\\"VMail Plan_no\\\",\\\"VMail Plan_yes\\\"],\\\"index\\\":[0,1],\\\"data\\\":[[128,25,265.1,110,45.07,197.4,99,16.78,244.7,91,11.01,10.0,3,2.7,1,1,0,0,1],[107,26,161.6,123,27.47,195.5,103,16.62,254.4,103,11.45,13.7,3,3.7,1,1,0,0,1]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>probs_no</th>\n",
       "      <th>probs_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred  probs_no  probs_yes\n",
       "0     0     0.975      0.975\n",
       "1     0     1.000      1.000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(res,orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
